import io
import os
import json
import streamlit as st
from google.cloud import vision
import google.generativeai as genai

# --- Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
st.set_page_config(page_title=" Mukawwin | Ù…ÙÙƒÙˆÙ‘ÙÙ†", layout="centered")
st.title(" Mukawwin | Ù…ÙÙƒÙˆÙ‘ÙÙ† ğŸ¤–")
st.write("Ø­Ù„Ù„ Ù…ÙƒÙˆÙ†Ø§Øª Ø£ÙŠ Ù…Ù†ØªØ¬ ØºØ°Ø§Ø¦ÙŠ Ø¹Ø¨Ø± Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø£Ùˆ Ø±ÙØ¹Ù‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©.")

# --- Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø§Øª Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª (APIs) ---
# Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙˆØŒ Ù…ØµÙ…Ù… Ù„Ù„Ø¹Ù…Ù„ Ù…Ø­Ù„ÙŠÙ‹Ø§ ÙˆÙ…Ø¹ Ø§Ù„Ù†Ø´Ø±
try:
    google_creds_json_str = st.secrets["gcp_service_account_json_str"]
    gemini_api_key = st.secrets["gemini_api_key"]
    with open("gcp-credentials.json", "w") as f:
        f.write(google_creds_json_str)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "gcp-credentials.json"
    genai.configure(api_key=gemini_api_key)
except (FileNotFoundError, KeyError):
    st.warning("ğŸ”‘ ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ù„Ù„ØªØ´ØºÙŠÙ„.", icon="âš ï¸")
    if "GEMINI_API_KEY" not in os.environ or "GOOGLE_APPLICATION_CREDENTIALS" not in os.environ:
        st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© GEMINI_API_KEY Ùˆ GOOGLE_APPLICATION_CREDENTIALS Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ù„ÙŠ.")
        st.stop()
    genai.configure(api_key=os.environ["GEMINI_API_KEY"])


# --- Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø®Ù„ÙÙŠ) ---
@st.cache_data
def get_text_from_image(image_content):
    """ÙŠØ³ØªØ®Ø¯Ù… Google Vision API Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©."""
    try:
        client = vision.ImageAnnotatorClient()
        image = vision.Image(content=image_content)
        response = client.text_detection(image=image)
        return response.text_annotations[0].description if response.text_annotations else None
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Google Vision: {e}")
        return None

# ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù…Ù† Ù‡Ù†Ø§ Ù„Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
def analyze_with_gemini(raw_text: str):
    """ÙŠØ³ØªØ®Ø¯Ù… Gemini API Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª."""
    model = genai.GenerativeModel('gemini-2.5-flash')
    prompt = """
Extract ingredient lists from the following texts. The ingredient list should start with the first ingredient and end with the last ingredient. It should not include allergy, label or origin information.
The output format must be a single JSON list containing one element per ingredient list. If there are ingredients in several languages, the output JSON list should contain as many elements as detected languages. Each element should have two fields:
- a "text" field containing the detected ingredient list. The text should be a substring of the original text, you must not alter the original text.
- a "lang" field containing the detected language of the ingredient list.
Don't output anything else than the expected JSON list.
    """
    full_prompt = f"{prompt}\n\n{raw_text}"
    try:
        response = model.generate_content(full_prompt)
        json_response = response.text.strip().lstrip("```json").rstrip("```")
        return json.loads(json_response)
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨ÙˆØ§Ø³Ø·Ø© Gemini: {e}")
        return None

# --- NEW: Create tabs for input options ---
tab1, tab2 = st.tabs(["ğŸ“· Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø©", "â¬†ï¸ Ø±ÙØ¹ Ù…Ù„Ù"])

with tab1:
    camera_photo = st.camera_input(
        "Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø© Ù„Ù…Ù„ØµÙ‚ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª", key="camera_uploader"
    )

with tab2:
    uploaded_file = st.file_uploader(
        "Ø£Ùˆ Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù…Ù† Ø¬Ù‡Ø§Ø²Ùƒ", type=["jpg", "jpeg", "png"], key="file_uploader"
    )

# --- Ù…Ù†Ø·Ù‚ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (Ù…ÙˆØ­Ø¯ Ù„ÙƒÙ„Ø§ Ø§Ù„Ø®ÙŠØ§Ø±ÙŠÙ†) ---
image_source = camera_photo or uploaded_file

if image_source is not None:
    st.image(image_source, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©", use_column_width=True)
    
    image_content = image_source.getvalue()
    
    with st.spinner("ğŸ§  Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø§Ù„Ø£Ù…Ø± Ø¨Ø¶Ø¹ Ø«ÙˆØ§Ù†Ù"):
        st.markdown("---")
        st.info("ğŸ‘ï¸ **Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Vision**")
        raw_text = get_text_from_image(image_content)
        
        if raw_text:
            with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬"):
                st.text_area("Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù…", raw_text, height=150)
            
            st.info("ğŸ¤– **Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini**")
            structured_ingredients = analyze_with_gemini(raw_text)
            
            if structured_ingredients:
                st.success("ğŸ‰ ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
                st.json(structured_ingredients)
            else:
                st.error("Ù„Ù… ÙŠØªÙ…ÙƒÙ† Gemini Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ.")
        else:
            st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù†Øµ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©.")